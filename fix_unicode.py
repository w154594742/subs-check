#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import re
import sys
import json

def fix_unicode_escapes(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å¤„ç†å½¢å¦‚ \\U0001F1FA\\U0001F1F8 çš„Unicodeè½¬ä¹‰åºåˆ—ï¼ˆå›½æ——ï¼‰
        content = re.sub(r'\\\\U0001F1[A-F0-9][A-F0-9]\\\\U0001F1[A-F0-9][A-F0-9]', 'å›½å®¶', content)
        content = re.sub(r'\\U0001F1[A-F0-9][A-F0-9]\\U0001F1[A-F0-9][A-F0-9]', 'å›½å®¶', content)
        
        # å¤„ç†å½¢å¦‚ "\\U0001F1EC\\U0001F1E7" çš„JSONæ ¼å¼Unicodeè½¬ä¹‰åºåˆ—
        def replace_json_unicode(match):
            try:
                # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                text = json.loads(match.group(0))
                return "å›½å®¶"
            except:
                return match.group(0)
        
        content = re.sub(r'"\\\\U0001F1[A-F0-9][A-F0-9]\\\\U0001F1[A-F0-9][A-F0-9]"', replace_json_unicode, content)
        
        # å¤„ç†å½¢å¦‚ \u4e2d\u56fd çš„Unicodeè½¬ä¹‰åºåˆ—
        def replace_unicode(match):
            try:
                # è·å–4ä½åå…­è¿›åˆ¶æ•°
                hex_val = match.group(1)
                # è½¬æ¢ä¸ºUnicodeå­—ç¬¦
                return chr(int(hex_val, 16))
            except:
                return match.group(0)
        
        # æ›¿æ¢ \u4e2d æ ¼å¼çš„Unicode
        content = re.sub(r'\\u([0-9a-fA-F]{4})', replace_unicode, content)
        
        # å¸¸è§çš„å›½å®¶åç§°
        country_names = [
            'æŒªå¨', 'ä¸­å›½', 'å°æ¹¾', 'é¦™æ¸¯', 'æ—¥æœ¬', 'éŸ©å›½', 'ç¾å›½', 'æ–°åŠ å¡', 'å°åº¦', 'ä¿„ç½—æ–¯',
            'è‹±å›½', 'å¾·å›½', 'æ³•å›½', 'æ„å¤§åˆ©', 'åŠ æ‹¿å¤§', 'æ¾³å¤§åˆ©äºš', 'è·å…°', 'ç‘å£«', 'ç‘å…¸', 'èŠ¬å…°',
            'ä¸¹éº¦', 'æ¯”åˆ©æ—¶', 'å¥¥åœ°åˆ©', 'è¥¿ç­ç‰™', 'è‘¡è„ç‰™', 'å¸Œè…Š', 'åœŸè€³å…¶', 'é˜¿è”é…‹', 'ä»¥è‰²åˆ—', 'æ²™ç‰¹',
            'å·´è¥¿', 'é˜¿æ ¹å»·', 'å¢¨è¥¿å“¥', 'å—é', 'åŸƒåŠ', 'æ³°å›½', 'é©¬æ¥è¥¿äºš', 'å°å°¼', 'è²å¾‹å®¾', 'è¶Šå—',
            'æŸ¬åŸ”å¯¨', 'ç¼…ç”¸', 'å°¼æ³Šå°”', 'å·´åŸºæ–¯å¦', 'å­ŸåŠ æ‹‰', 'æ–¯é‡Œå…°å¡', 'å“ˆè¨å…‹æ–¯å¦', 'ä¹Œå…¹åˆ«å…‹æ–¯å¦', 'ä¹Œå…‹å…°', 'ç™½ä¿„ç½—æ–¯',
            'æ³¢å…°', 'æ·å…‹', 'åŒˆç‰™åˆ©', 'ç½—é©¬å°¼äºš', 'ä¿åŠ åˆ©äºš', 'å¡å°”ç»´äºš'
        ]

        # é¦–å…ˆé¢„å¤„ç†å¸¸è§é—®é¢˜æ ¼å¼
        
        # 1. å¤„ç†"å›½å†…"ç²˜è¿é—®é¢˜ï¼Œä¸ºå¸¸è§å›½å®¶åç§°å’Œ"å›½å†…"ä¹‹é—´æ·»åŠ ç©ºæ ¼ä¾¿äºåç»­å¤„ç†
        for country in country_names:
            content = re.sub(f'({country})å›½å†…', f'\\1 å›½å†…', content)
        
        # 2. æ¸…ç†å½¢å¦‚ "2|æœç²¾ 3" çš„æ•°å­—å‰ç¼€
        content = re.sub(r'(name: ["\']).?\|[^|]+\|', r'\1', content)
        content = re.sub(r'(ps: ["\']).?\|[^|]+\|', r'\1', content)
        
        # 3. æ¸…ç†ç‰¹å®šæœåŠ¡å•†æ ‡è¯†å’ŒåŸŸå
        service_providers = [
            'CloudFlare', 'cloudflare', 'AWS', 'AZURE', 'GCP', 
            'Oracle', 'oracle', 'Azure', 'aws',
            'æƒå¨å•†', 'ç‹¸åºŠåºŠ', 'æœç²¾', 'V2CROSS', 'v2cross', 
            'ORACLE', 'LINODE', 'linode', 'DO', 'Vultr', 'vultr',
            'GIA', 'gia', 'IPLC', 'iplc', 'BGP', 'bgp', 'CN2', 'cn2'
        ]
        
        # æ¸…ç†èŠ‚ç‚¹åç§°ä¸­çš„æœåŠ¡å•†æ ‡è¯†
        for provider in service_providers:
            content = re.sub(f'(name: ["\'])[^"\']*{provider}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
            content = re.sub(f'(ps: ["\'])[^"\']*{provider}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        
        # 4. æ¸…ç†å¸¦æœ‰ç‰¹æ®Šç¬¦å·çš„èŠ‚ç‚¹åç§°
        special_chars = r'[â™¦â˜…â˜†â—†â—â—â—‹â–²â–³â–¼â–½â—‡â–¡â– ã€ã€‘ã€Œã€â¤ï¸ğŸ’•ğŸ’—ğŸ’ğŸ’˜â¤]'
        content = re.sub(f'(name: ["\'])[^"\']*{special_chars}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        content = re.sub(f'(ps: ["\'])[^"\']*{special_chars}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        
        # 5. å¤„ç†éš§é“å›å›½ç‚¹
        content = re.sub(r'(name: ["\'])éš§é“å›å›½ç‚¹[^\'"]*(["\'])', r'\1å›å›½èŠ‚ç‚¹\2', content)
        content = re.sub(r'(ps: ["\'])éš§é“å›å›½ç‚¹[^\'"]*(["\'])', r'\1å›å›½èŠ‚ç‚¹\2', content)
        
        # 6. å¤„ç†å¸¦ç½‘å€å’ŒIPçš„èŠ‚ç‚¹
        content = re.sub(r'(name: ["\'])[^\'"]*((?:\d{1,3}\.){3}\d{1,3})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(ps: ["\'])[^\'"]*((?:\d{1,3}\.){3}\d{1,3})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(name: ["\'])[^\'"]*((?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(ps: ["\'])[^\'"]*((?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        
        # 7. å¤„ç†å¸¦æœ‰é€Ÿåº¦æ ‡è¯†çš„èŠ‚ç‚¹åç§°ï¼ˆä¾‹å¦‚ï¼š5.8MB/sï¼‰
        content = re.sub(r'(name: ["\'])[^"\']*\d+\.?\d*\s*[KMG]B\/s[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        content = re.sub(r'(ps: ["\'])[^"\']*\d+\.?\d*\s*[KMG]B\/s[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        
        # æœ€åæ¸…ç†ä»»ä½•å‰©ä½™çš„"å›½å†…"æ–‡æœ¬
        content = re.sub(r'å›½å†…\s+', '', content)
        content = re.sub(r'\s+å›½å†…', '', content)
        content = re.sub(r'æŒªå›½å†…', 'æŒªå¨', content)
        
        # æ¸…ç†ç»“æœä¸­å¯èƒ½å‡ºç°çš„å¤šä¸ªç©ºæ ¼
        content = re.sub(r'(name: ["\']\s*)(èŠ‚ç‚¹)(\s*["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(ps: ["\']\s*)(èŠ‚ç‚¹)(\s*["\'])', r'\1èŠ‚ç‚¹\3', content)
        
        # å†™å›æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return True
    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        return False

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python fix_unicode.py <æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    file_path = sys.argv[1]
    success = fix_unicode_escapes(file_path)
    
    if success:
        print(f"æˆåŠŸå¤„ç†æ–‡ä»¶: {file_path}")
    else:
        print(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path}")
        sys.exit(1) 