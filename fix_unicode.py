#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import re
import sys
import json

def fix_unicode_escapes(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å¤„ç†å½¢å¦‚ \\U0001F1FA\\U0001F1F8 çš„Unicodeè½¬ä¹‰åºåˆ—ï¼ˆå›½æ——ï¼‰
        content = re.sub(r'\\\\U0001F1[A-F0-9][A-F0-9]\\\\U0001F1[A-F0-9][A-F0-9]', 'å›½å®¶', content)
        content = re.sub(r'\\U0001F1[A-F0-9][A-F0-9]\\U0001F1[A-F0-9][A-F0-9]', 'å›½å®¶', content)
        
        # å¤„ç†å½¢å¦‚ "\\U0001F1EC\\U0001F1E7" çš„JSONæ ¼å¼Unicodeè½¬ä¹‰åºåˆ—
        def replace_json_unicode(match):
            try:
                # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                text = json.loads(match.group(0))
                return "\"å›½å®¶\""
            except:
                return match.group(0)
        
        content = re.sub(r'"\\\\U0001F1[A-F0-9][A-F0-9]\\\\U0001F1[A-F0-9][A-F0-9]"', replace_json_unicode, content)
        
        # å¤„ç†å½¢å¦‚ \u4e2d\u56fd çš„Unicodeè½¬ä¹‰åºåˆ—
        def replace_unicode(match):
            try:
                # è·å–4ä½åå…­è¿›åˆ¶æ•°
                hex_val = match.group(1)
                # è½¬æ¢ä¸ºUnicodeå­—ç¬¦
                return chr(int(hex_val, 16))
            except:
                return match.group(0)
        
        # æ›¿æ¢ \u4e2d æ ¼å¼çš„Unicode
        content = re.sub(r'\\u([0-9a-fA-F]{4})', replace_unicode, content)
        
        # ----- èŠ‚ç‚¹åç§°æ¸…ç† -----
        
        # ä¸“é—¨å¤„ç†nameå’Œpså­—æ®µ
        lines = content.split('\n')
        processed_lines = []
        
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦æ˜¯nameæˆ–psè¡Œ
            if re.match(r'\s*name:\s*["\']', line) or re.match(r'\s*ps:\s*["\']', line):
                # å½»åº•ç®€åŒ–èŠ‚ç‚¹åç§°ï¼Œåªä¿ç•™"èŠ‚ç‚¹"
                if "æƒå¨å•†" in line or "ç‹¸åºŠåºŠ" in line or "CloudFlare" in line or "cloudflare" in line:
                    # æå–å¼•å·ç±»å‹ï¼ˆå•å¼•å·æˆ–åŒå¼•å·ï¼‰
                    quote_match = re.search(r'(name|ps):\s*(["\'])', line)
                    if quote_match:
                        quote_type = quote_match.group(2)
                        field_type = quote_match.group(1)
                        # é‡æ„æ•´è¡Œï¼Œåªä¿ç•™"èŠ‚ç‚¹"
                        line = re.sub(r'(name|ps):\s*["\'].*?["\']', f'{field_type}: {quote_type}èŠ‚ç‚¹{quote_type}', line)
            
            processed_lines.append(line)
        
        content = '\n'.join(processed_lines)
        
        # ----- å¸¸è§„å¤„ç†æµç¨‹ -----
        
        # å¸¸è§çš„å›½å®¶åç§°
        country_names = [
            'æŒªå¨', 'ä¸­å›½', 'å°æ¹¾', 'é¦™æ¸¯', 'æ—¥æœ¬', 'éŸ©å›½', 'ç¾å›½', 'æ–°åŠ å¡', 'å°åº¦', 'ä¿„ç½—æ–¯',
            'è‹±å›½', 'å¾·å›½', 'æ³•å›½', 'æ„å¤§åˆ©', 'åŠ æ‹¿å¤§', 'æ¾³å¤§åˆ©äºš', 'è·å…°', 'ç‘å£«', 'ç‘å…¸', 'èŠ¬å…°',
            'ä¸¹éº¦', 'æ¯”åˆ©æ—¶', 'å¥¥åœ°åˆ©', 'è¥¿ç­ç‰™', 'è‘¡è„ç‰™', 'å¸Œè…Š', 'åœŸè€³å…¶', 'é˜¿è”é…‹', 'ä»¥è‰²åˆ—', 'æ²™ç‰¹',
            'å·´è¥¿', 'é˜¿æ ¹å»·', 'å¢¨è¥¿å“¥', 'å—é', 'åŸƒåŠ', 'æ³°å›½', 'é©¬æ¥è¥¿äºš', 'å°å°¼', 'è²å¾‹å®¾', 'è¶Šå—',
            'æŸ¬åŸ”å¯¨', 'ç¼…ç”¸', 'å°¼æ³Šå°”', 'å·´åŸºæ–¯å¦', 'å­ŸåŠ æ‹‰', 'æ–¯é‡Œå…°å¡', 'å“ˆè¨å…‹æ–¯å¦', 'ä¹Œå…¹åˆ«å…‹æ–¯å¦', 'ä¹Œå…‹å…°', 'ç™½ä¿„ç½—æ–¯',
            'æ³¢å…°', 'æ·å…‹', 'åŒˆç‰™åˆ©', 'ç½—é©¬å°¼äºš', 'ä¿åŠ åˆ©äºš', 'å¡å°”ç»´äºš'
        ]
        
        # æœåŠ¡å•†å’Œç‰¹æ®Šå­—ç¬¦æ ‡è¯†
        service_providers = [
            'CloudFlare', 'cloudflare', 'AWS', 'AZURE', 'GCP', 'Oracle', 'oracle', 'Azure', 'aws',
            'æƒå¨å•†', 'ç‹¸åºŠåºŠ', 'æœç²¾', 'V2CROSS', 'v2cross', 'éš§é“', 'ä¸“çº¿', 'ä¸­ç»§', 'ç‹¬äº«', 
            'ORACLE', 'LINODE', 'linode', 'DO', 'Vultr', 'vultr', 'BandwagonHost', 'bandwagonhost',
            'GIA', 'gia', 'IPLC', 'iplc', 'BGP', 'bgp', 'CN2', 'cn2', 'GT', 'IEPL', 'iepl',
            'é«˜çº§', 'æ ‡å‡†', 'å®éªŒ', 'ä»˜è´¹', 'å…è´¹', 'ç™½å«–', 'ä½“éªŒ', 'æµ‹è¯•', 'TEST', 'test', 
            'æ¸¸æˆ', 'è§†é¢‘', 'ç½‘ç«™', 'ç›´è¿', 'ä¸­è½¬', 'ä¸“ç”¨', 'åŸç”Ÿ', 'æ™®é€š', 'ä¼˜é€‰', 
            'â™¦', 'â˜…', 'â˜†', 'â—†', 'â—', 'â—', 'â—‹', 'â–²', 'â–³', 'â–¼', 'â–½', 'â—‡', 'â–¡', 'â– ', 'ã€', 'ã€‘', 'ã€Œ', 'ã€',
            'â¤ï¸', 'ğŸ’•', 'ğŸ’—', 'ğŸ’', 'ğŸ’˜', 'â¤', 
            'Netease', 'netease', 'Telegram', 'telegram', 'Youtube', 'youtube', 'TikTok', 'tiktok',
            'Disney', 'disney', 'Netflix', 'netflix', 'HBO', 'hbo', 'Hulu', 'hulu'
        ]
        
        # 1. å¤„ç†åç§°+å›½å†…çš„é—®é¢˜
        for country in country_names:
            content = re.sub(f'({country})å›½å†…', f'\\1', content)
        
        # 2. å¤„ç†ç‰¹å®šæœåŠ¡æ ‡è¯†
        for provider in service_providers:
            content = re.sub(f'(name:\s*["\'])[^"\']*{re.escape(provider)}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content, flags=re.IGNORECASE)
            content = re.sub(f'(ps:\s*["\'])[^"\']*{re.escape(provider)}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content, flags=re.IGNORECASE)
        
        # 3. æ¸…ç†å½¢å¦‚ "2|æœç²¾ 3" çš„æ•°å­—å‰ç¼€
        content = re.sub(r'(name:\s*["\']).?\|[^|]+\|', r'\1', content)
        content = re.sub(r'(ps:\s*["\']).?\|[^|]+\|', r'\1', content)
        
        # 4. å¤„ç†å¸¦ç½‘å€å’ŒIPçš„èŠ‚ç‚¹
        content = re.sub(r'(name:\s*["\'])[^\'"]*((?:\d{1,3}\.){3}\d{1,3})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(ps:\s*["\'])[^\'"]*((?:\d{1,3}\.){3}\d{1,3})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(name:\s*["\'])[^\'"]*((?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(ps:\s*["\'])[^\'"]*((?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,})[^\'"]*(["\'])', r'\1èŠ‚ç‚¹\3', content)
        
        # 5. å¤„ç†å¸¦æœ‰é€Ÿåº¦æ ‡è¯†çš„èŠ‚ç‚¹åç§°ï¼ˆä¾‹å¦‚ï¼š5.8MB/sï¼‰
        content = re.sub(r'(name:\s*["\'])[^"\']*\d+\.?\d*\s*[KMG]B\/s[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        content = re.sub(r'(ps:\s*["\'])[^"\']*\d+\.?\d*\s*[KMG]B\/s[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        
        # 6. å¤„ç†å‰©ä½™çš„èŠ‚ç‚¹åç§°ï¼ˆå¦‚æœä»æœ‰å¸¦|çš„æ ¼å¼ï¼‰
        content = re.sub(r'(name:\s*["\'])[^"\'\|]*\|[^"\'\|]*\|[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        content = re.sub(r'(ps:\s*["\'])[^"\'\|]*\|[^"\'\|]*\|[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content)
        
        # 7. æ¸…ç†æœ€å¸¸è§çš„ç‰¹å®šåç§°
        specific_names = [
            'æƒå¨å•†', 'ç‹¸åºŠåºŠ', 'CloudFlare', 'cloudflare', 'æœç²¾',
            'éš§é“å›å›½ç‚¹', 'V2CROSS.COM', 'v2cross.com', 'ä¸“çº¿'
        ]
        for name in specific_names:
            content = re.sub(f'(name:\s*["\'])[^"\']*{re.escape(name)}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content, flags=re.IGNORECASE)
            content = re.sub(f'(ps:\s*["\'])[^"\']*{re.escape(name)}[^"\']*(["\'])', r'\1èŠ‚ç‚¹\2', content, flags=re.IGNORECASE)
        
        # 8. æœ€åæ¸…ç†å‰©ä½™çš„ç‰¹æ®Šå­—ç¬¦å’Œå›½å†…æ ‡è¯†
        content = re.sub(r'å›½å†…\s+', '', content)
        content = re.sub(r'\s+å›½å†…', '', content)
        content = re.sub(r'æŒªå›½å†…', 'æŒªå¨', content)
        
        # 9. æ¸…ç†ç»“æœä¸­å¯èƒ½å‡ºç°çš„å¤šä¸ªç©ºæ ¼å’Œé‡å¤èŠ‚ç‚¹åç§°
        content = re.sub(r'(name:\s*["\']\s*)(èŠ‚ç‚¹)(\s*["\'])', r'\1èŠ‚ç‚¹\3', content)
        content = re.sub(r'(ps:\s*["\']\s*)(èŠ‚ç‚¹)(\s*["\'])', r'\1èŠ‚ç‚¹\3', content)
        
        # å†™å›æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return True
    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        return False

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python fix_unicode.py <æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    file_path = sys.argv[1]
    success = fix_unicode_escapes(file_path)
    
    if success:
        print(f"æˆåŠŸå¤„ç†æ–‡ä»¶: {file_path}")
    else:
        print(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path}")
        sys.exit(1) 